<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/marked/4.0.2/marked.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #000;
            color: #fff;
            overflow: hidden;
        }
        .container {
            text-align: center;
            padding: 2rem;
            max-width: 80%;
            width: 600px;
            position: relative;
        }
        .clock {
            position: absolute;
            top: -10%;
            left: 50%;
            transform: translateX(-50%);
            font-size: 6rem;
            color: #fff;
            z-index: 0;
            font-weight: bold;
        }
        #character {
            font-size: 180px;
            animation: hover 2s ease-in-out infinite;
            z-index: 1;
        }
        @keyframes hover {
            0% { transform: translateY(0); }
            50% { transform: translateY(-10px); }
            100% { transform: translateY(0); }
        }
        #response-text {
            margin-top: 2rem;
            font-size: 1.2rem;
            min-height: 1.5em;
        }
        #status {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 1rem;
            opacity: 0.7;
        }
        #longform-ui {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: #000;
            z-index: 1000;
            overflow-y: auto;
            padding: 2rem;
            box-sizing: border-box;
        }
        #longform-content {
            max-width: 800px;
            margin: 0 auto;
            color: #fff;
            font-size: 1.2rem;
            line-height: 1.6;
            position: relative;
            margin-top: 3rem;
        }
        #longform-content::before {
            content: 'ðŸ¤–';
            position: absolute;
            top: -4rem;
            left: 0;
            font-size: 3rem;
        }
        #longform-content::after {
            content: attr(data-time);
            position: absolute;
            top: -4rem;
            right: 0;
            font-size: 1.5rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="home-ui">
            <div class="clock" id="clock"></div>
            <div id="character">ðŸ¤–</div>
            <div id="response-text"></div>
        </div>
    </div>
    <div id="status">Press and hold spacebar to speak</div>
    <div id="longform-ui">
        <div id="longform-content"></div>
    </div>

    <script>
        const status = document.getElementById('status');
        const responseText = document.getElementById('response-text');
        const homeUI = document.getElementById('home-ui');
        const character = document.getElementById('character');
        const longformUI = document.getElementById('longform-ui');
        const longformContent = document.getElementById('longform-content');
        let recognition;
        let conversationHistory = [];
        let isPlayingMusic = false;

        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                addMessageToConversation('user', transcript);
                sendMessageToServer(transcript);
            };

            recognition.onerror = function(event) {
                console.error('Speech recognition error', event.error);
                status.textContent = 'Error: ' + event.error;
            };
        } else {
            status.textContent = 'Speech Recognition Not Supported';
        }

        document.body.onkeydown = function(e) {
            if (e.keyCode == 32 && e.target == document.body) {
                e.preventDefault();
                if (longformUI.style.display === 'block') {
                    closeLongformUI();
                } else if (recognition && !recognition.isRecording) {
                    status.textContent = 'Listening...';
                    recognition.start();
                    recognition.isRecording = true;
                }
            }
        };

        document.body.onkeyup = function(e) {
            if (e.keyCode == 32) {
                if (recognition && recognition.isRecording) {
                    recognition.stop();
                    recognition.isRecording = false;
                    status.textContent = 'Processing...';
                }
            }
        };

        function addMessageToConversation(role, content) {
            conversationHistory.push({role: role, content: content});
            if (role === 'assistant') {
                displayResponseText(content);
            }
        }

        function displayResponseText(text) {
            if (text.includes('â€¢') || text.includes('#') || text.includes('```') || text.includes('*') || text.includes('_')) {
                openLongformUI(text);
            } else {
                const lines = text.split('\n').filter(line => line.trim() !== '');
                let currentLine = 0;

                function showNextLine() {
                    if (currentLine < lines.length) {
                        responseText.innerHTML = marked.parse(lines[currentLine]);
                        currentLine++;
                        setTimeout(showNextLine, 5000);
                    }
                }

                showNextLine();
            }
        }

        function openLongformUI(content) {
            const currentTime = new Date().toLocaleTimeString('en-GB', { hour: '2-digit', minute: '2-digit' });
            longformContent.setAttribute('data-time', currentTime);
            longformContent.innerHTML = marked.parse(content);
            longformUI.style.display = 'block';
            status.textContent = 'Hold spacebar to exit';
        }

        function closeLongformUI() {
            longformUI.style.display = 'none';
            status.textContent = 'Press and hold spacebar to speak';
        }

        function toggleMusicIcon(isPlaying) {
            if (isPlaying) {
                character.textContent = 'ðŸ¤–ðŸŽµðŸŽ¶';
                isPlayingMusic = true;
            } else {
                character.textContent = 'ðŸ¤–';
                isPlayingMusic = false;
            }
        }

        function updateClock() {
            const currentTime = new Date().toLocaleTimeString('en-GB', { hour: '2-digit', minute: '2-digit'});
            document.getElementById('clock').textContent = currentTime;
            setTimeout(updateClock, 1000);
        }

        updateClock();

        function sendMessageToServer(message) {
            fetch('/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ 
                    message: message,
                    conversation: conversationHistory
                }),
            })
            .then(response => response.body.getReader())
            .then(reader => readStream(reader))
            .catch(error => {
                console.error('Error:', error);
                status.textContent = 'Error occurred. Try again.';
            });
        }

        async function readStream(reader) {
            const decoder = new TextDecoder();
            let buffer = '';
            let chunkCount = 0;
            
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                
                buffer += decoder.decode(value, { stream: true });
                
                console.log(`Received chunk ${++chunkCount}:`, buffer);  // Debug log
                
                let boundary = buffer.indexOf('\n');
                while (boundary !== -1) {
                    const chunk = buffer.substring(0, boundary);
                    buffer = buffer.substring(boundary + 1);
                    
                    console.log(`Processing chunk:`, chunk);  // Debug log
                    
                    if (chunk.trim().length > 0) {
                        try {
                            const jsonResponse = JSON.parse(chunk);
                            handleServerResponse(jsonResponse);
                        } catch (error) {
                            console.error('Error parsing JSON:', error);
                            console.error('Problematic chunk:', chunk);
                        }
                    }
                    
                    boundary = buffer.indexOf('\n');
                }
            }
        }

        function handleServerResponse(response) {
            if (response.type === 'content') {
                displayAssistantMessage(response.text);
            } else if (response.type === 'audio') {
                playAudioStream(response.id);
            } else {
                console.warn('Unknown response type:', response.type);
            }
        }

        function displayAssistantMessage(text) {
            addMessageToConversation('assistant', text);
        }
        
        async function playAudioStream(audioId) {
            try {
                const response = await fetch(`/stream_audio/${audioId}`);
                const arrayBuffer = await response.arrayBuffer();
                
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const sampleRate = 44100; // Make sure this matches your server's sample rate
                const channelCount = 1;  // Mono audio

                // Convert the raw PCM data to a Float32Array
                const floatArray = new Float32Array(arrayBuffer);
                
                // Create an AudioBuffer
                const audioBuffer = audioContext.createBuffer(channelCount, floatArray.length, sampleRate);
                
                // Copy the float data to the AudioBuffer
                audioBuffer.copyToChannel(floatArray, 0);

                // Create a BufferSource and play it
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start(0);
                
                console.log('Audio playback started');
            } catch (error) {
                console.error('Error playing audio:', error);
            }
        }
    </script>
</body>
</html>